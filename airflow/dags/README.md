# Airflow DAGs

ì´ ë””ë ‰í† ë¦¬ëŠ” PostgreSQL ë°ì´í„° ë³µì‚¬ ë° DBT ì²˜ë¦¬ë¥¼ ìœ„í•œ Airflow DAGë“¤ì„ í¬í•¨í•©ë‹ˆë‹¤.

## ğŸ“‹ DAG ëª©ë¡

### 1. `postgres_data_copy_dag.py`
**ë©”ì¸ ë°ì´í„° ë³µì‚¬ DAG**

- **ê¸°ëŠ¥**: PostgreSQL ì†ŒìŠ¤ì—ì„œ íƒ€ê²Ÿìœ¼ë¡œ ë°ì´í„° ë³µì‚¬
- **ìŠ¤ì¼€ì¤„**: ë§¤ì¼ ì‹¤í–‰ (`@daily`)
- **ì£¼ìš” íŠ¹ì§•**:
  - ë‹¤ì¤‘ í…Œì´ë¸” ìˆœì°¨ ì²˜ë¦¬
  - ì¦ë¶„ ë™ê¸°í™” ì§€ì›
  - ìë™ ìŠ¤í‚¤ë§ˆ ê°ì§€ ë° ìƒì„±
  - ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦
  - DBT ìŠ¤ëƒ…ìƒ· ìë™ ìƒì„±

### 2. `postgres_data_copy_dag_refactored.py`
**ë¦¬íŒ©í† ë§ëœ ë°ì´í„° ë³µì‚¬ DAG**

- **ê¸°ëŠ¥**: ê°œì„ ëœ êµ¬ì¡°ì™€ ëª¨ë‹ˆí„°ë§ì„ ê°–ì¶˜ ë°ì´í„° ë³µì‚¬
- **ìŠ¤ì¼€ì¤„**: ë§¤ì¼ ì˜¤ì „ 3ì‹œ, ì˜¤í›„ 4ì‹œ (`0 3,16 * * *`)
- **ì£¼ìš” íŠ¹ì§•**:
  - ëª¨ë“ˆí™”ëœ êµ¬ì¡°
  - í–¥ìƒëœ ì—ëŸ¬ í•¸ë“¤ë§
  - ìƒì„¸í•œ ëª¨ë‹ˆí„°ë§ ë° ì²´í¬í¬ì¸íŠ¸
  - DBT íŒŒì´í”„ë¼ì¸ í†µí•©

### 3. `dbt_processing_dag.py`
**DBT ì²˜ë¦¬ DAG**

- **ê¸°ëŠ¥**: DBT ëª¨ë¸, ìŠ¤ëƒ…ìƒ·, í…ŒìŠ¤íŠ¸ ì‹¤í–‰
- **ìŠ¤ì¼€ì¤„**: ìˆ˜ë™ ì‹¤í–‰ ë˜ëŠ” ì˜ì¡´ì„± ê¸°ë°˜
- **ì£¼ìš” íŠ¹ì§•**:
  - DBT ëª…ë ¹ì–´ ì‹¤í–‰
  - ëª¨ë¸ ê°„ ì˜ì¡´ì„± ê´€ë¦¬
  - í…ŒìŠ¤íŠ¸ ê²°ê³¼ ê²€ì¦

### 4. `main_orchestration_dag.py`
**ë©”ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ DAG**

- **ê¸°ëŠ¥**: ì „ì²´ ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì¡°ìœ¨
- **ìŠ¤ì¼€ì¤„**: ìˆ˜ë™ ì‹¤í–‰
- **ì£¼ìš” íŠ¹ì§•**:
  - ë°ì´í„° ë³µì‚¬ â†’ DBT ì²˜ë¦¬ â†’ ê²€ì¦ ìˆœì°¨ ì‹¤í–‰
  - ì „ì²´ ì›Œí¬í”Œë¡œìš° ìƒíƒœ ê´€ë¦¬

### 5. `data_copy_dag.py`
**ê¸°ë³¸ ë°ì´í„° ë³µì‚¬ DAG**

- **ê¸°ëŠ¥**: ë‹¨ìˆœí•œ ë°ì´í„° ë³µì‚¬ ì‘ì—…
- **ìŠ¤ì¼€ì¤„**: ìˆ˜ë™ ì‹¤í–‰
- **ì£¼ìš” íŠ¹ì§•**:
  - ê¸°ë³¸ì ì¸ ë°ì´í„° ë³µì‚¬ ê¸°ëŠ¥
  - ê°„ë‹¨í•œ ì„¤ì •

### 6. `simple_postgres_copy_dag.py`
**ê°„ë‹¨í•œ PostgreSQL ë³µì‚¬ DAG**

- **ê¸°ëŠ¥**: ë‹¨ì¼ í…Œì´ë¸” ë³µì‚¬
- **ìŠ¤ì¼€ì¤„**: ìˆ˜ë™ ì‹¤í–‰
- **ì£¼ìš” íŠ¹ì§•**:
  - ìµœì†Œí•œì˜ ì„¤ì •ìœ¼ë¡œ ë¹ ë¥¸ ë³µì‚¬
  - í•™ìŠµ ë° í…ŒìŠ¤íŠ¸ìš©

### 7. `variable_setup_dag.py`
**ë³€ìˆ˜ ì„¤ì • DAG**

- **ê¸°ëŠ¥**: Airflow ë³€ìˆ˜ ë° ì—°ê²° ì„¤ì •
- **ìŠ¤ì¼€ì¤„**: ìˆ˜ë™ ì‹¤í–‰
- **ì£¼ìš” íŠ¹ì§•**:
  - í™˜ê²½ë³„ ì„¤ì • ê´€ë¦¬
  - ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì •ë³´ ì„¤ì •

### 8. `cosmos_dbt_dag.py` / `cosmos_dbt_docs_dag.py`
**Cosmos DBT DAGë“¤**

- **ê¸°ëŠ¥**: Cosmosë¥¼ ì‚¬ìš©í•œ DBT ì‹¤í–‰
- **ìŠ¤ì¼€ì¤„**: ìˆ˜ë™ ì‹¤í–‰
- **ì£¼ìš” íŠ¹ì§•**:
  - Cosmos DBT í†µí•©
  - ë¬¸ì„œ ìƒì„±

## ğŸ—ï¸ ê³µí†µ ëª¨ë“ˆ (`common/`)

### `data_copy_engine.py`
ë°ì´í„° ë³µì‚¬ ì—”ì§„ì˜ í•µì‹¬ ë¡œì§ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.

**ì£¼ìš” ê¸°ëŠ¥**:
- ìŠ¤ë§ˆíŠ¸ ìŠ¤í‚¤ë§ˆ ê°ì§€
- ë°ì´í„° íƒ€ì… ìë™ ë³€í™˜
- CSV ì½ê¸°/ì“°ê¸° ìµœì í™”
- ë°°ì¹˜ ì²˜ë¦¬
- MERGE ì‘ì—… ìˆ˜í–‰

**í•µì‹¬ ë©”ì„œë“œ**:
```python
def copy_data_with_custom_sql(self, source_table: str, target_table: str, ...)
def _validate_and_convert_data_types(self, df: pd.DataFrame, table_name: str)
def create_temp_table_and_import_csv(self, target_table: str, ...)
```

### `database_operations.py`
ë°ì´í„°ë² ì´ìŠ¤ ì‘ì—…ì„ ìœ„í•œ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ì„ ì œê³µí•©ë‹ˆë‹¤.

**ì£¼ìš” ê¸°ëŠ¥**:
- í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ ì¡°íšŒ
- í…Œì´ë¸” ìƒì„± ë° ê²€ì¦
- í–‰ ìˆ˜ ê³„ì‚°
- ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦

**í•µì‹¬ ë©”ì„œë“œ**:
```python
def get_table_schema(self, table_name: str) -> dict
def create_table_if_not_exists(self, target_table: str, source_schema: dict)
def verify_data_integrity(self, source_table: str, target_table: str, ...)
```

## âš™ï¸ ì„¤ì • ë° ì‚¬ìš©ë²•

### ê¸°ë³¸ ì„¤ì •

ê° DAGëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì„¤ì •ì„ ì§€ì›í•©ë‹ˆë‹¤:

```python
table_config = {
    "source": "schema.table_name",           # ì†ŒìŠ¤ í…Œì´ë¸”
    "target": "schema.table_name",           # íƒ€ê²Ÿ í…Œì´ë¸”
    "primary_key": ["id"],                   # ê¸°ë³¸í‚¤
    "sync_mode": "incremental_sync",         # ë™ê¸°í™” ëª¨ë“œ
    "incremental_field": "updated_at",       # ì¦ë¶„ í•„ë“œ
    "incremental_field_type": "timestamp",   # ì¦ë¶„ í•„ë“œ íƒ€ì…
    "batch_size": 10000,                     # ë°°ì¹˜ í¬ê¸°
    "custom_where": "status = 'active'",     # ì‚¬ìš©ì ì •ì˜ WHERE ì¡°ê±´
    "custom_select": "SELECT * FROM ...",    # ì‚¬ìš©ì ì •ì˜ SELECT
    "custom_count": "SELECT COUNT(*) FROM ..." # ì‚¬ìš©ì ì •ì˜ COUNT
}
```

### ë™ê¸°í™” ëª¨ë“œ

1. **`full_sync`**: ì „ì²´ ë°ì´í„° ë³µì‚¬
   - ê¸°ì¡´ ë°ì´í„° ì‚­ì œ í›„ ìƒˆë¡œ ì‚½ì…
   - ë°ì´í„° ë¬´ê²°ì„± ë³´ì¥

2. **`incremental_sync`**: ì¦ë¶„ ë°ì´í„° ë³µì‚¬
   - ë³€ê²½ëœ ë°ì´í„°ë§Œ ë³µì‚¬
   - ì„±ëŠ¥ ìµœì í™”

### ì¦ë¶„ í•„ë“œ íƒ€ì…

- **`timestamp`**: íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ë°˜
- **`yyyymmdd`**: ë‚ ì§œ ê¸°ë°˜ (YYYYMMDD í˜•ì‹)
- **`date`**: ë‚ ì§œ ê¸°ë°˜
- **`datetime`**: ë‚ ì§œì‹œê°„ ê¸°ë°˜

## ğŸ“Š ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…

### ì²´í¬í¬ì¸íŠ¸ ì‹œìŠ¤í…œ

ë¦¬íŒ©í† ë§ëœ DAGëŠ” ì²´í¬í¬ì¸íŠ¸ ì‹œìŠ¤í…œì„ í†µí•´ ê° ë‹¨ê³„ì˜ ì§„í–‰ ìƒí™©ì„ ì¶”ì í•©ë‹ˆë‹¤:

```python
monitoring.add_checkpoint("ìŠ¤í‚¤ë§ˆ ì¡°íšŒ", "ì†ŒìŠ¤ í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ ì¡°íšŒ ì™„ë£Œ")
monitoring.add_checkpoint("ë°ì´í„° ë³µì‚¬", "ë°ì´í„° ë³µì‚¬ ì™„ë£Œ")
monitoring.add_checkpoint("DBT ì‹¤í–‰", "DBT ìŠ¤ëƒ…ìƒ· ìƒì„± ì™„ë£Œ")
```

### ë¡œê·¸ ë ˆë²¨

- **INFO**: ì¼ë°˜ì ì¸ ì§„í–‰ ìƒí™©
- **WARNING**: ì£¼ì˜ê°€ í•„ìš”í•œ ìƒí™©
- **ERROR**: ì˜¤ë¥˜ ìƒí™©
- **DEBUG**: ìƒì„¸í•œ ë””ë²„ê¹… ì •ë³´

## ğŸ”§ ê³ ê¸‰ ê¸°ëŠ¥

### ì‚¬ìš©ì ì •ì˜ SQL

ì†ŒìŠ¤ ë°ì´í„°ì— ë³µì¡í•œ ë³€í™˜ì´ í•„ìš”í•œ ê²½ìš° ì‚¬ìš©ì ì •ì˜ SQLì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
table_config = {
    "custom_select": """
        SELECT 
            id,
            name,
            CASE 
                WHEN priority ~ '^[0-9]+\\.[0-9]+$' 
                THEN CAST(CAST(priority AS NUMERIC) AS BIGINT)::TEXT
                ELSE priority 
            END AS priority,
            updated_at
        FROM source_table
        WHERE status = 'active'
    """,
    "custom_count": "SELECT COUNT(*) FROM source_table WHERE status = 'active'"
}
```

### ë°ì´í„° íƒ€ì… ë³€í™˜

ì—”ì§„ì€ ìë™ìœ¼ë¡œ ë°ì´í„° íƒ€ì…ì„ ë³€í™˜í•©ë‹ˆë‹¤:

- **BIGINT/INTEGER**: ì†Œìˆ˜ì  ê°’ â†’ ì •ìˆ˜ ë³€í™˜
- **VARCHAR**: ë¹ˆ ë¬¸ìì—´ â†’ NULL ë³€í™˜
- **TIMESTAMP**: ë‚ ì§œ í˜•ì‹ ìë™ ë³€í™˜

### ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”

ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ë¥¼ ìœ„í•œ ë°°ì¹˜ ì²˜ë¦¬:

```python
# ë°°ì¹˜ í¬ê¸° ì¡°ì •
table_config["batch_size"] = 5000  # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì— ë”°ë¼ ì¡°ì •

# ì§„í–‰ë¥  ë¡œê¹…
logger.info(f"INSERT ì§„í–‰ë¥ : {total_inserted}/{len(df_reordered)}")
```

## ğŸš¨ ì—ëŸ¬ í•¸ë“¤ë§

### ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜

```python
def _verify_table_schema_with_retry(self, target_table: str, source_schema: dict, max_retries: int = 3):
    for attempt in range(max_retries):
        try:
            # ìŠ¤í‚¤ë§ˆ ê²€ì¦ ë¡œì§
            return target_schema
        except Exception as e:
            if attempt < max_retries - 1:
                wait_time = (attempt + 1) * 2
                logger.warning(f"ìŠ¤í‚¤ë§ˆ ê²€ì¦ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}): {e}, {wait_time}ì´ˆ í›„ ì¬ì‹œë„")
                time.sleep(wait_time)
            else:
                raise
```

### ìƒì„¸í•œ ì—ëŸ¬ ë¡œê¹…

```python
logger.error(f"ë°ì´í„° ë³µì‚¬ ì‹¤íŒ¨: {source_table} -> {target_table}")
logger.error(f"ì˜¤ë¥˜ ìƒì„¸: {e}")
logger.error(f"ì»¨í…ìŠ¤íŠ¸: {context}")
```

## ğŸ“ˆ ì„±ëŠ¥ ìµœì í™”

### ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”

1. **ë°°ì¹˜ í¬ê¸° ì¡°ì •**: ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ê³¼ ì„±ëŠ¥ì˜ ê· í˜•
2. **ë°ì´í„°í”„ë ˆì„ ì²­ì†Œ**: ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì œê±°
3. **ê°€ë¹„ì§€ ì»¬ë ‰ì…˜**: ì£¼ê¸°ì ì¸ ë©”ëª¨ë¦¬ ì •ë¦¬

### ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ìµœì í™”

1. **ì—°ê²° í’€ë§**: íš¨ìœ¨ì ì¸ ì—°ê²° ê´€ë¦¬
2. **ì„¸ì…˜ ê²©ë¦¬**: í•˜ë‚˜ì˜ ì—°ê²°ì—ì„œ ì—¬ëŸ¬ ì‘ì—… ìˆ˜í–‰
3. **íŠ¸ëœì­ì…˜ ê´€ë¦¬**: ì ì ˆí•œ ì»¤ë°‹ ì‹œì 

## ğŸ” ë””ë²„ê¹…

### ë¡œê·¸ ë¶„ì„

```bash
# Airflow ë¡œê·¸ í™•ì¸
airflow tasks logs postgres_multi_table_copy copy_data_with_dynamic_sql 2024-01-01T00:00:00

# íŠ¹ì • íƒœìŠ¤í¬ì˜ ë¡œê·¸
airflow tasks logs postgres_multi_table_copy validate_data_integrity 2024-01-01T00:00:00
```

### ë°ì´í„° ê²€ì¦

```python
# ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦
validation_result = validate_data_integrity(table_config, **context)
logger.info(f"ê²€ì¦ ê²°ê³¼: {validation_result}")
```

## ğŸ“š ì¶”ê°€ ë¦¬ì†ŒìŠ¤

- [Airflow ê³µì‹ ë¬¸ì„œ](https://airflow.apache.org/docs/)
- [DBT ê³µì‹ ë¬¸ì„œ](https://docs.getdbt.com/)
- [PostgreSQL ê³µì‹ ë¬¸ì„œ](https://www.postgresql.org/docs/)
- [í”„ë¡œì íŠ¸ ë©”ì¸ README](../../README.md)

---

**ì°¸ê³ **: ì´ DAGë“¤ì€ í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ì‚¬ìš©í•˜ê¸° ì „ì— ì¶©ë¶„í•œ í…ŒìŠ¤íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤. íŠ¹íˆ ë°ì´í„° í¬ê¸°ì™€ ì„±ëŠ¥ ìš”êµ¬ì‚¬í•­ì„ ê³ ë ¤í•˜ì—¬ ì„¤ì •ì„ ì¡°ì •í•˜ì„¸ìš”.

## ğŸ”— ì—°ê²° ê´€ë¦¬

### ì—°ê²° ì •ë³´ ìš°ì„ ìˆœìœ„

í”„ë¡œì íŠ¸ì—ì„œëŠ” ë‹¤ìŒê³¼ ê°™ì€ ìš°ì„ ìˆœìœ„ë¡œ ì—°ê²° ì •ë³´ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤:

1. **Airflow Connection** (ìµœìš°ì„ ) - ì™¸ë¶€ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
2. **Airflow Variables** (ë‘ ë²ˆì§¸) - ì„¤ì • ì •ë³´
3. **í™˜ê²½ë³€ìˆ˜** (ì„¸ ë²ˆì§¸) - Docker Compose ë‚´ë¶€ DB ì •ë³´
4. **ê¸°ë³¸ê°’** (ìµœí›„) - í•˜ë“œì½”ë”©ëœ ê¸°ë³¸ê°’

### ConnectionManager ì‚¬ìš©ë²•

```python
from common.connection_manager import ConnectionManager

# ì—°ê²° í…ŒìŠ¤íŠ¸
is_connected = ConnectionManager.test_connection("digitalocean_postgres")

# ì—°ê²° ì •ë³´ ê°€ì ¸ì˜¤ê¸°
conn_info = ConnectionManager.get_connection_info("digitalocean_postgres")

# ëª¨ë“  ì—°ê²° ìƒíƒœ ìš”ì•½
summary = ConnectionManager.get_connection_summary()

# í•„ìˆ˜ ì—°ê²° ê²€ì¦
required_connections = ["digitalocean_postgres", "postgres_default"]
validation_results = ConnectionManager.validate_required_connections(required_connections)
```

### ì™¸ë¶€ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„¤ì •

ì™¸ë¶€ ë°ì´í„°ë² ì´ìŠ¤(ì˜ˆ: DigitalOcean PostgreSQL)ëŠ” Airflow UIì—ì„œ Connectionìœ¼ë¡œ ì„¤ì •:

1. Airflow UI â†’ Admin â†’ Connections
2. ìƒˆ ì—°ê²° ì¶”ê°€
3. ì—°ê²° ID, í˜¸ìŠ¤íŠ¸, í¬íŠ¸, ì‚¬ìš©ìëª…, ë¹„ë°€ë²ˆí˜¸ ì…ë ¥

### ë‚´ë¶€ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°

Docker Compose ë‚´ë¶€ ë°ì´í„°ë² ì´ìŠ¤ëŠ” `.env` íŒŒì¼ë¡œ ê´€ë¦¬:

```bash
# .env íŒŒì¼
POSTGRES_HOST=10.150.2.150
POSTGRES_USER=airflow
POSTGRES_PASSWORD=airflow
POSTGRES_DB=airflow
POSTGRES_PORT=15432
```
