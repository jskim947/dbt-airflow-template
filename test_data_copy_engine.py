#!/usr/bin/env python3
"""
DataCopyEngine í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ìƒˆë¡œ ì¶”ê°€ëœ ì›Œì»¤ ì„¤ì •ê³¼ xmin ê´€ë ¨ ë©”ì„œë“œë“¤ì„ í…ŒìŠ¤íŠ¸
"""

import sys
import os
import logging

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def test_worker_config():
    """ì›Œì»¤ ì„¤ì • í…ŒìŠ¤íŠ¸"""
    try:
        from airflow.dags.common.settings import BatchSettings
        
        logger.info("=== ì›Œì»¤ ì„¤ì • í…ŒìŠ¤íŠ¸ ===")
        
        # ì›Œì»¤ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
        worker_config = BatchSettings.get_worker_config()
        logger.info(f"ì›Œì»¤ ì„¤ì •: {worker_config}")
        
        # í™˜ê²½ë³„ ì„¤ì • í™•ì¸
        env = os.getenv("AIRFLOW_ENV", "development")
        logger.info(f"í˜„ì¬ í™˜ê²½: {env}")
        
        # ê¸°ë³¸ê°’ í™•ì¸
        assert "default_workers" in worker_config
        assert "max_workers" in worker_config
        assert "min_workers" in worker_config
        
        logger.info("âœ… ì›Œì»¤ ì„¤ì • í…ŒìŠ¤íŠ¸ í†µê³¼")
        return True
        
    except Exception as e:
        logger.error(f"âŒ ì›Œì»¤ ì„¤ì • í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def test_batch_settings():
    """ë°°ì¹˜ ì„¤ì • í…ŒìŠ¤íŠ¸"""
    try:
        from airflow.dags.common.settings import BatchSettings
        
        logger.info("=== ë°°ì¹˜ ì„¤ì • í…ŒìŠ¤íŠ¸ ===")
        
        # ë°°ì¹˜ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
        batch_config = BatchSettings.get_batch_config()
        logger.info(f"ë°°ì¹˜ ì„¤ì •: {batch_config}")
        
        # í…Œì´ë¸”ë³„ ë°°ì¹˜ í¬ê¸° í™•ì¸
        table_batch_sizes = {
            "ì¸í¬ë§¥ìŠ¤ì¢…ëª©ë§ˆìŠ¤í„°": BatchSettings.get_table_specific_batch_size("ì¸í¬ë§¥ìŠ¤ì¢…ëª©ë§ˆìŠ¤í„°"),
            "ff_v3_ff_sec_entity": BatchSettings.get_table_specific_batch_size("ff_v3_ff_sec_entity"),
            "edi_690": BatchSettings.get_table_specific_batch_size("edi_690"),
        }
        
        logger.info(f"í…Œì´ë¸”ë³„ ë°°ì¹˜ í¬ê¸°: {table_batch_sizes}")
        
        # ê¸°ë³¸ê°’ í™•ì¸
        assert "default_batch_size" in batch_config
        assert "parallel_workers" in batch_config
        
        logger.info("âœ… ë°°ì¹˜ ì„¤ì • í…ŒìŠ¤íŠ¸ í†µê³¼")
        return True
        
    except Exception as e:
        logger.error(f"âŒ ë°°ì¹˜ ì„¤ì • í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def test_xmin_settings():
    """xmin ì„¤ì • í…ŒìŠ¤íŠ¸"""
    try:
        from airflow.dags.common.settings import DAGSettings
        
        logger.info("=== xmin ì„¤ì • í…ŒìŠ¤íŠ¸ ===")
        
        # xmin ì„¤ì • ê°€ì ¸ì˜¤ê¸°
        xmin_settings = DAGSettings.get_xmin_settings()
        logger.info(f"xmin ì„¤ì •: {xmin_settings}")
        
        # xmin í…Œì´ë¸” ì„¤ì • ê°€ì ¸ì˜¤ê¸°
        xmin_table_configs = DAGSettings.get_xmin_table_configs()
        logger.info(f"xmin í…Œì´ë¸” ì„¤ì •: {xmin_table_configs}")
        
        # ê¸°ë³¸ê°’ í™•ì¸
        assert "enable_xmin_tracking" in xmin_settings
        assert "xmin_column_name" in xmin_settings
        assert "batch_size_multiplier" in xmin_settings
        
        logger.info("âœ… xmin ì„¤ì • í…ŒìŠ¤íŠ¸ í†µê³¼")
        return True
        
    except Exception as e:
        logger.error(f"âŒ xmin ì„¤ì • í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def test_environment_config():
    """í™˜ê²½ ì„¤ì • í…ŒìŠ¤íŠ¸"""
    try:
        from airflow.dags.common.settings import DAGSettings
        
        logger.info("=== í™˜ê²½ ì„¤ì • í…ŒìŠ¤íŠ¸ ===")
        
        # í™˜ê²½ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
        env_config = DAGSettings.get_environment_config()
        logger.info(f"í™˜ê²½ ì„¤ì •: {env_config}")
        
        # í™˜ê²½ë³„ ë°°ì¹˜ í¬ê¸° í™•ì¸
        env = os.getenv("AIRFLOW_ENV", "development")
        logger.info(f"í˜„ì¬ í™˜ê²½: {env}")
        logger.info(f"í™˜ê²½ë³„ ë°°ì¹˜ í¬ê¸°: {env_config.get('batch_size', 'N/A')}")
        
        # ê¸°ë³¸ê°’ í™•ì¸
        assert "batch_size" in env_config
        assert "debug" in env_config
        assert "log_level" in env_config
        
        logger.info("âœ… í™˜ê²½ ì„¤ì • í…ŒìŠ¤íŠ¸ í†µê³¼")
        return True
        
    except Exception as e:
        logger.error(f"âŒ í™˜ê²½ ì„¤ì • í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    logger.info("ğŸš€ DataCopyEngine ë° ì„¤ì • í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    test_results = []
    
    # ê° í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    test_results.append(("ì›Œì»¤ ì„¤ì •", test_worker_config()))
    test_results.append(("ë°°ì¹˜ ì„¤ì •", test_batch_settings()))
    test_results.append(("xmin ì„¤ì •", test_xmin_settings()))
    test_results.append(("í™˜ê²½ ì„¤ì •", test_environment_config()))
    
    # ê²°ê³¼ ìš”ì•½
    logger.info("\n=== í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½ ===")
    passed = 0
    total = len(test_results)
    
    for test_name, result in test_results:
        status = "âœ… í†µê³¼" if result else "âŒ ì‹¤íŒ¨"
        logger.info(f"{test_name}: {status}")
        if result:
            passed += 1
    
    logger.info(f"\nì´ {total}ê°œ í…ŒìŠ¤íŠ¸ ì¤‘ {passed}ê°œ í†µê³¼ ({passed/total*100:.1f}%)")
    
    if passed == total:
        logger.info("ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼!")
        return 0
    else:
        logger.error("ğŸ’¥ ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
        return 1

if __name__ == "__main__":
    sys.exit(main()) 