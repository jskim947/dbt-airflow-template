#!/usr/bin/env python3
"""
ê°œì„ ëœ ì²­í¬ ë°©ì‹ ë°ì´í„° ë³µì‚¬ ì—”ì§„ í…ŒìŠ¤íŠ¸

ì½”ë“œ ë¦¬ë·°ì—ì„œ ì œì•ˆëœ ê°œì„ ì‚¬í•­ë“¤ì´ ë°˜ì˜ëœ í›„
ê¸°ëŠ¥ì´ ì •ìƒì ìœ¼ë¡œ ë™ì‘í•˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
"""

import unittest
from unittest.mock import Mock, patch, MagicMock
import tempfile
import os
import json
import time

# í…ŒìŠ¤íŠ¸í•  ëª¨ë“ˆë“¤
from airflow.dags.common.constants import (
    ChunkModeDefaults,
    MemoryThresholds,
    BatchSizeDefaults,
    RetryDefaults,
    get_table_size_category,
    get_optimal_batch_size,
    get_optimal_retry_count
)

class TestImprovedChunkEngine(unittest.TestCase):
    """ê°œì„ ëœ ì²­í¬ ì—”ì§„ í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""

    def setUp(self):
        """í…ŒìŠ¤íŠ¸ ì„¤ì •"""
        self.temp_dir = tempfile.mkdtemp()
        
    def tearDown(self):
        """í…ŒìŠ¤íŠ¸ ì •ë¦¬"""
        import shutil
        shutil.rmtree(self.temp_dir, ignore_errors=True)

    def test_chunk_mode_defaults(self):
        """ì²­í¬ ë°©ì‹ ê¸°ë³¸ ì„¤ì • ìƒìˆ˜ í…ŒìŠ¤íŠ¸"""
        self.assertTrue(ChunkModeDefaults.DEFAULT_CHUNK_MODE)
        self.assertTrue(ChunkModeDefaults.DEFAULT_ENABLE_CHECKPOINT)
        self.assertEqual(ChunkModeDefaults.DEFAULT_MAX_RETRIES, 3)
        self.assertEqual(ChunkModeDefaults.DEFAULT_BATCH_SIZE, 10000)

    def test_memory_thresholds(self):
        """ë©”ëª¨ë¦¬ ì„ê³„ê°’ ìƒìˆ˜ í…ŒìŠ¤íŠ¸"""
        self.assertEqual(MemoryThresholds.WARNING_MB, 500)
        self.assertEqual(MemoryThresholds.CRITICAL_MB, 1000)
        self.assertEqual(MemoryThresholds.EMERGENCY_MB, 1500)
        
        # ì„ê³„ê°’ ìˆœì„œ ê²€ì¦
        self.assertLess(MemoryThresholds.WARNING_MB, MemoryThresholds.CRITICAL_MB)
        self.assertLess(MemoryThresholds.CRITICAL_MB, MemoryThresholds.EMERGENCY_MB)

    def test_batch_size_defaults(self):
        """ë°°ì¹˜ í¬ê¸° ê¸°ë³¸ê°’ ìƒìˆ˜ í…ŒìŠ¤íŠ¸"""
        self.assertEqual(BatchSizeDefaults.SMALL_TABLE, 1000)
        self.assertEqual(BatchSizeDefaults.MEDIUM_TABLE, 5000)
        self.assertEqual(BatchSizeDefaults.LARGE_TABLE, 10000)
        self.assertEqual(BatchSizeDefaults.XLARGE_TABLE, 15000)
        
        # ë°°ì¹˜ í¬ê¸° ìˆœì„œ ê²€ì¦
        self.assertLess(BatchSizeDefaults.SMALL_TABLE, BatchSizeDefaults.MEDIUM_TABLE)
        self.assertLess(BatchSizeDefaults.MEDIUM_TABLE, BatchSizeDefaults.LARGE_TABLE)
        self.assertLess(BatchSizeDefaults.LARGE_TABLE, BatchSizeDefaults.XLARGE_TABLE)

    def test_retry_defaults(self):
        """ì¬ì‹œë„ íšŸìˆ˜ ê¸°ë³¸ê°’ ìƒìˆ˜ í…ŒìŠ¤íŠ¸"""
        self.assertEqual(RetryDefaults.SMALL_TABLE, 2)
        self.assertEqual(RetryDefaults.MEDIUM_TABLE, 3)
        self.assertEqual(RetryDefaults.LARGE_TABLE, 5)
        self.assertEqual(RetryDefaults.XLARGE_TABLE, 7)
        
        # ì¬ì‹œë„ íšŸìˆ˜ ìˆœì„œ ê²€ì¦
        self.assertLess(RetryDefaults.SMALL_TABLE, RetryDefaults.MEDIUM_TABLE)
        self.assertLess(RetryDefaults.MEDIUM_TABLE, RetryDefaults.LARGE_TABLE)
        self.assertLess(RetryDefaults.LARGE_TABLE, RetryDefaults.XLARGE_TABLE)

    def test_table_size_category_classification(self):
        """í…Œì´ë¸” í¬ê¸° ë¶„ë¥˜ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸"""
        # ì†Œìš©ëŸ‰ í…Œì´ë¸”
        self.assertEqual(get_table_size_category(50000), "small")
        self.assertEqual(get_table_size_category(100000), "small")
        
        # ì¤‘ê°„ í¬ê¸° í…Œì´ë¸”
        self.assertEqual(get_table_size_category(100001), "medium")
        self.assertEqual(get_table_size_category(500000), "medium")
        self.assertEqual(get_table_size_category(1000000), "medium")
        
        # ëŒ€ìš©ëŸ‰ í…Œì´ë¸”
        self.assertEqual(get_table_size_category(1000001), "large")
        self.assertEqual(get_table_size_category(5000000), "large")
        self.assertEqual(get_table_size_category(10000000), "large")
        
        # ì´ˆëŒ€ìš©ëŸ‰ í…Œì´ë¸”
        self.assertEqual(get_table_size_category(10000001), "xlarge")
        self.assertEqual(get_table_size_category(50000000), "xlarge")

    def test_optimal_batch_size_calculation(self):
        """ìµœì  ë°°ì¹˜ í¬ê¸° ê³„ì‚° í•¨ìˆ˜ í…ŒìŠ¤íŠ¸"""
        # ê°œë°œ í™˜ê²½
        dev_batch_size = get_optimal_batch_size("medium", "development")
        self.assertEqual(dev_batch_size, 2000)  # 1000 * 2.0
        
        # ìŠ¤í…Œì´ì§• í™˜ê²½
        staging_batch_size = get_optimal_batch_size("large", "staging")
        self.assertEqual(staging_batch_size, 25000)  # 5000 * 5.0
        
        # í”„ë¡œë•ì…˜ í™˜ê²½
        prod_batch_size = get_optimal_batch_size("xlarge", "production")
        self.assertEqual(prod_batch_size, 100000)  # 10000 * 10.0
        
        # ê¸°ë³¸ê°’ (í”„ë¡œë•ì…˜)
        default_batch_size = get_optimal_batch_size("small")
        self.assertEqual(default_batch_size, 10000)  # 10000 * 1.0

    def test_optimal_retry_count_calculation(self):
        """ìµœì  ì¬ì‹œë„ íšŸìˆ˜ ê³„ì‚° í•¨ìˆ˜ í…ŒìŠ¤íŠ¸"""
        self.assertEqual(get_optimal_retry_count("small"), 2)
        self.assertEqual(get_optimal_retry_count("medium"), 3)
        self.assertEqual(get_optimal_retry_count("large"), 5)
        self.assertEqual(get_optimal_retry_count("xlarge"), 7)
        
        # ì•Œ ìˆ˜ ì—†ëŠ” ì¹´í…Œê³ ë¦¬
        self.assertEqual(get_optimal_retry_count("unknown"), 3)  # ê¸°ë³¸ê°’

    def test_constants_consistency(self):
        """ìƒìˆ˜ë“¤ ê°„ì˜ ì¼ê´€ì„± í…ŒìŠ¤íŠ¸"""
        # ë°°ì¹˜ í¬ê¸°ì™€ ì¬ì‹œë„ íšŸìˆ˜ì˜ ìƒê´€ê´€ê³„ ê²€ì¦
        # ì¼ë°˜ì ìœ¼ë¡œ ë°°ì¹˜ í¬ê¸°ê°€ í´ìˆ˜ë¡ ì¬ì‹œë„ íšŸìˆ˜ë„ ë§ì•„ì•¼ í•¨
        small_retries = get_optimal_retry_count("small")
        large_retries = get_optimal_retry_count("large")
        self.assertLess(small_retries, large_retries)
        
        # ë©”ëª¨ë¦¬ ì„ê³„ê°’ê³¼ ë°°ì¹˜ í¬ê¸°ì˜ ìƒê´€ê´€ê³„ ê²€ì¦
        # ë°°ì¹˜ í¬ê¸°ê°€ í´ìˆ˜ë¡ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ì¦ê°€í•˜ë¯€ë¡œ ì„ê³„ê°’ë„ ë†’ì•„ì•¼ í•¨
        small_batch = BatchSizeDefaults.SMALL_TABLE
        large_batch = BatchSizeDefaults.LARGE_TABLE
        self.assertLess(small_batch, large_batch)

    def test_environment_defaults_structure(self):
        """í™˜ê²½ë³„ ê¸°ë³¸ ì„¤ì • êµ¬ì¡° í…ŒìŠ¤íŠ¸"""
        from airflow.dags.common.constants import EnvironmentDefaults
        
        # ëª¨ë“  í™˜ê²½ì— í•„ìš”í•œ í‚¤ê°€ ìˆëŠ”ì§€ í™•ì¸
        required_keys = ["debug", "log_level", "email_notifications", "retries", "batch_size"]
        
        for env_name in ["DEVELOPMENT", "STAGING", "PRODUCTION"]:
            env_config = getattr(EnvironmentDefaults, env_name)
            for key in required_keys:
                self.assertIn(key, env_config, f"{env_name}ì— {key} í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤")

    def test_sync_modes_constants(self):
        """ë™ê¸°í™” ëª¨ë“œ ìƒìˆ˜ í…ŒìŠ¤íŠ¸"""
        from airflow.dags.common.constants import SyncModes
        
        self.assertEqual(SyncModes.FULL_SYNC, "full_sync")
        self.assertEqual(SyncModes.INCREMENTAL_SYNC, "incremental_sync")
        self.assertEqual(SyncModes.XMIN_INCREMENTS, "xmin_incremental")
        self.assertEqual(SyncModes.HYBRID_INCREMENTS, "hybrid_incremental")
        
        # ëª¨ë“  ëª¨ë“œê°€ ê³ ìœ í•œ ê°’ì¸ì§€ í™•ì¸
        modes = [
            SyncModes.FULL_SYNC,
            SyncModes.INCREMENTAL_SYNC,
            SyncModes.XMIN_INCREMENTS,
            SyncModes.HYBRID_INCREMENTS
        ]
        self.assertEqual(len(modes), len(set(modes)))

    def test_error_types_constants(self):
        """ì—ëŸ¬ íƒ€ì… ìƒìˆ˜ í…ŒìŠ¤íŠ¸"""
        from airflow.dags.common.constants import ErrorTypes
        
        self.assertEqual(ErrorTypes.CONNECTION_ERROR, "connection_error")
        self.assertEqual(ErrorTypes.DATA_ERROR, "data_error")
        self.assertEqual(ErrorTypes.INTERNAL_ERROR, "internal_error")
        self.assertEqual(ErrorTypes.TIMEOUT_ERROR, "timeout_error")
        self.assertEqual(ErrorTypes.MEMORY_ERROR, "memory_error")

    def test_file_extensions_constants(self):
        """íŒŒì¼ í™•ì¥ì ìƒìˆ˜ í…ŒìŠ¤íŠ¸"""
        from airflow.dags.common.constants import FileExtensions
        
        self.assertEqual(FileExtensions.CSV, ".csv")
        self.assertEqual(FileExtensions.JSON, ".json")
        self.assertEqual(FileExtensions.CHECKPOINT, ".checkpoint")
        self.assertEqual(FileExtensions.BACKUP, ".backup")

    def test_database_defaults_constants(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ê¸°ë³¸ ì„¤ì • ìƒìˆ˜ í…ŒìŠ¤íŠ¸"""
        from airflow.dags.common.constants import DatabaseDefaults
        
        self.assertEqual(DatabaseDefaults.DEFAULT_PORT, 5432)
        self.assertEqual(DatabaseDefaults.DEFAULT_SCHEMA, "public")
        self.assertEqual(DatabaseDefaults.DEFAULT_TIMEOUT, 30)
        self.assertEqual(DatabaseDefaults.DEFAULT_CHUNK_SIZE, 10000)

    def test_performance_thresholds_constants(self):
        """ì„±ëŠ¥ ì„ê³„ê°’ ìƒìˆ˜ í…ŒìŠ¤íŠ¸"""
        from airflow.dags.common.constants import PerformanceThresholds
        
        self.assertEqual(PerformanceThresholds.COPY_TIME_SECONDS, 300)
        self.assertEqual(PerformanceThresholds.MEMORY_USAGE_MB, 1024)
        self.assertEqual(PerformanceThresholds.ERROR_RATE_PERCENT, 5.0)

    def test_config_versions_constants(self):
        """ì„¤ì • ë²„ì „ ìƒìˆ˜ í…ŒìŠ¤íŠ¸"""
        from airflow.dags.common.constants import ConfigVersions
        
        self.assertEqual(ConfigVersions.CURRENT_VERSION, "1.0.0")
        self.assertEqual(ConfigVersions.MIN_SUPPORTED_VERSION, "1.0.0")
        self.assertEqual(ConfigVersions.CONFIG_SCHEMA_VERSION, "1.0")

    def test_constants_immutability(self):
        """ìƒìˆ˜ ë¶ˆë³€ì„± í…ŒìŠ¤íŠ¸"""
        # ìƒìˆ˜ë“¤ì´ ì‹¤ì œë¡œ ìƒìˆ˜ì¸ì§€ í™•ì¸ (ëŸ°íƒ€ì„ì— ë³€ê²½ë˜ì§€ ì•ŠëŠ”ì§€)
        original_warning = MemoryThresholds.WARNING_MB
        
        # ìƒìˆ˜ ë³€ê²½ ì‹œë„ (ì‹¤ì œë¡œëŠ” ë³€ê²½ë˜ì§€ ì•Šì•„ì•¼ í•¨)
        try:
            MemoryThresholds.WARNING_MB = 999
            # ë§Œì•½ ë³€ê²½ëœë‹¤ë©´ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨
            self.assertEqual(MemoryThresholds.WARNING_MB, original_warning)
        except Exception:
            # ìƒìˆ˜ê°€ ë³€ê²½ ë¶ˆê°€ëŠ¥í•˜ë‹¤ë©´ ì˜ˆì™¸ ë°œìƒ (ì •ìƒ)
            pass
        
        # ì›ë˜ ê°’ í™•ì¸
        self.assertEqual(MemoryThresholds.WARNING_MB, original_warning)

def run_performance_test():
    """ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("ğŸš€ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    start_time = time.time()
    
    # í…Œì´ë¸” í¬ê¸°ë³„ ìµœì  ë°°ì¹˜ í¬ê¸° ê³„ì‚° ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
    for i in range(10000):
        get_optimal_batch_size("large", "production")
        get_optimal_retry_count("xlarge")
    
    end_time = time.time()
    execution_time = end_time - start_time
    
    print(f"âœ… ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {execution_time:.4f}ì´ˆ")
    print(f"   - 10,000íšŒ í•¨ìˆ˜ í˜¸ì¶œ")
    print(f"   - í‰ê·  ì‹¤í–‰ ì‹œê°„: {execution_time/10000:.6f}ì´ˆ/í˜¸ì¶œ")
    
    return execution_time

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸ§ª ê°œì„ ëœ ì²­í¬ ì—”ì§„ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 50)
    
    # ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    print("1. ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰...")
    unittest.main(argv=[''], exit=False, verbosity=2)
    
    print("\n" + "=" * 50)
    
    # ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    print("2. ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰...")
    performance_time = run_performance_test()
    
    print("\n" + "=" * 50)
    print("ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    
    # í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½
    if performance_time < 1.0:  # 1ì´ˆ ì´ë‚´ ì‹¤í–‰
        print("âœ… ì„±ëŠ¥: ìš°ìˆ˜")
    elif performance_time < 5.0:  # 5ì´ˆ ì´ë‚´ ì‹¤í–‰
        print("âœ… ì„±ëŠ¥: ì–‘í˜¸")
    else:
        print("âš ï¸  ì„±ëŠ¥: ê°œì„  í•„ìš”")

if __name__ == "__main__":
    main() 